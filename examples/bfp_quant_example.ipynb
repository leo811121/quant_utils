{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use bfp quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tensor: tensor([[[0.5672, 0.4827, 0.9736, 0.9933, 0.7408, 0.6750, 0.5733, 0.8217,\n",
      "          0.6145, 0.3059, 0.6476, 0.5216, 0.0475, 0.4384, 0.8723, 0.0060,\n",
      "          0.3065, 0.6823, 0.7041, 0.2682, 0.5052, 0.1543, 0.8035, 0.0273,\n",
      "          0.9714, 0.8638, 0.8233, 0.1421, 0.8525, 0.9548, 0.1369, 0.2375],\n",
      "         [0.5342, 0.1822, 0.0692, 0.9360, 0.0337, 0.7143, 0.3309, 0.8532,\n",
      "          0.1549, 0.3195, 0.4839, 0.7720, 0.1671, 0.3358, 0.4266, 0.8087,\n",
      "          0.8182, 0.4397, 0.6347, 0.1417, 0.6291, 0.7128, 0.4986, 0.2885,\n",
      "          0.6457, 0.7820, 0.7390, 0.6818, 0.8719, 0.0830, 0.8875, 0.4806]]],\n",
      "       device='cuda:0')\n",
      "dequantized tensor: tensor([[[0.5625, 0.4766, 0.9688, 0.9922, 0.7344, 0.6719, 0.5703, 0.8203,\n",
      "          0.6094, 0.3047, 0.6406, 0.5156, 0.0469, 0.4375, 0.8672, 0.0039,\n",
      "          0.3047, 0.6797, 0.7031, 0.2656, 0.5000, 0.1484, 0.7969, 0.0234,\n",
      "          0.9688, 0.8594, 0.8203, 0.1406, 0.8516, 0.9531, 0.1328, 0.2344],\n",
      "         [0.5312, 0.1797, 0.0625, 0.9297, 0.0312, 0.7109, 0.3281, 0.8516,\n",
      "          0.1484, 0.3125, 0.4766, 0.7656, 0.1641, 0.3281, 0.4219, 0.8047,\n",
      "          0.8125, 0.4375, 0.6328, 0.1406, 0.6250, 0.7109, 0.4922, 0.2812,\n",
      "          0.6406, 0.7812, 0.7344, 0.6797, 0.8672, 0.0781, 0.8828, 0.4766]]],\n",
      "       device='cuda:0')\n",
      "MAE: 0.003846148494631052\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import quantUtils\n",
    "\n",
    "x = torch.rand((1, 2, 32), dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "# quantization\n",
    "x_quant, x_scales = quantUtils.bfp_quantize(x, 16)\n",
    "\n",
    "# dequantization\n",
    "x_dequant = quantUtils.bfp_dequantize(x_quant, x_scales)\n",
    "\n",
    "# mean abs error\n",
    "mae = torch.mean(torch.abs(x - x_dequant))\n",
    "\n",
    "print(f\"original tensor: {x}\")\n",
    "print(f\"dequantized tensor: {x_dequant}\")\n",
    "print(f\"MAE: {mae}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmquant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
